{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "import os, os.path\n",
    "import sys\n",
    "sys.path.insert(0,'../processing/')\n",
    "sys.path.insert(0,'../')\n",
    "from datasets import sythtextprovider\n",
    "from nets import txtbox_300, textbox_common, np_methods\n",
    "#from processing import image_processing\n",
    "from image_processing2 import *\n",
    "from processing import ssd_vgg_preprocessing, visualization,txt_preprocessing\n",
    "import tf_utils\n",
    "import time\n",
    "slim = tf.contrib.slim\n",
    "import load_batch\n",
    "import numpy as np\n",
    "import skimage.io as skio\n",
    "from processing import tf_image\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "isess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6.0, 45.0),\n",
       " (46.79999999999999, 90.0),\n",
       " (87.6, 135.0),\n",
       " (128.4, 180.0),\n",
       " (169.2, 225.0),\n",
       " (210.0, 270.0)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_sizes=[(30., 60.),\n",
    "          (60., 114.),\n",
    "          (114., 168.),\n",
    "          (168., 222.),\n",
    "          (222., 276.),\n",
    "          (276., 330.)]\n",
    "anchor_sizes=[(30., 45.),\n",
    "              (45., 99.),\n",
    "              (99., 153.),\n",
    "              (153., 207.),\n",
    "              (207., 261.),\n",
    "              (261., 315.)]\n",
    "scale_range=[0.02, 0.7]\n",
    "scale_range_max = [0.15, 0.9]\n",
    "scales = [scale_range[0] + i*(scale_range[1] - scale_range[0])/5  for i in range(6)]\n",
    "scales_max = [scale_range_max[0] + i*(scale_range_max[1] - scale_range_max[0])/5  for i in range(6)]\n",
    "anchor_sizes = [(300*scales[i], 300*scales_max[i]) for i in range(6)]\n",
    "anchor_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_shape (300, 300)\n",
      "0.5\n",
      "file_path: ../data/ICDAR2013/*.tfrecord\n",
      "21\n",
      "2890\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(): \n",
    "    # build a net\\\n",
    "    params = txtbox_300.TextboxNet.default_params\n",
    "    #params = params._replace(anchor_sizes = anchor_sizes)\n",
    "    text_net = txtbox_300.TextboxNet(params)\n",
    "    text_shape = text_net.params.img_shape\n",
    "    print 'text_shape '+  str(text_shape)\n",
    "    text_anchors = text_net.anchors(text_shape)\n",
    "    print text_net.params.match_threshold\n",
    "    \n",
    "    ## dataset provider\n",
    "    dataset = sythtextprovider.get_datasets('../data/ICDAR2013/',file_pattern='*.tfrecord')\n",
    "    \n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "            dataset, common_queue_capacity=32, common_queue_min=2)\n",
    "    \n",
    "    [image, shape, glabels, gbboxes] = \\\n",
    "    data_provider.get(['image', 'shape',\n",
    "                     'object/label',\n",
    "                     'object/bbox'])\n",
    "    \n",
    "    dst_image, glabels, gbboxes,num = \\\n",
    "    txt_preprocessing.preprocess_image(image,  glabels,gbboxes, \n",
    "                                            text_shape,is_training=True)\n",
    "    \n",
    "    #image = (dst_image - tf.reduce_min(dst_image))/ (tf.reduce_max(dst_image) - tf.reduce_min(dst_image))\n",
    "    glocalisations, gscores = \\\n",
    "    text_net.bboxes_encode( gbboxes, text_anchors, num)\n",
    "    for i in range(6):\n",
    "        glocalisations[i] = tf.expand_dims(glocalisations[i], axis=0)\n",
    "        gscores[i] = tf.expand_dims(gscores[i], axis=0)\n",
    "    \n",
    "    with tf.Session() as sess: \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        with slim.queues.QueueRunners(sess):\n",
    "            error = []\n",
    "            box = []\n",
    "            for i in xrange(200):\n",
    "                rpredictions, rlocalisations, img ,gbboxes_= sess.run([gscores, glocalisations,dst_image,gbboxes])\n",
    "                rpredictions_2 = list(rpredictions)\n",
    "                localb = []\n",
    "                for i in range(6):\n",
    "                    decodeb = np_methods.ssd_bboxes_decode(rlocalisations[i],text_anchors[i])\n",
    "                    localb.append(decodeb[np.where(rpredictions[i] > 0.5)])\n",
    "                    pre2 = np.expand_dims(1-rpredictions[i], -1)\n",
    "                    rpredictions[i] = np.concatenate([pre2, np.expand_dims(rpredictions[i], -1)],axis = -1)\n",
    "                rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n",
    "                        rpredictions, rlocalisations, text_anchors,\n",
    "                        select_threshold=0.001, img_shape=text_shape, num_classes=2, decode=True)\n",
    "\n",
    "                rbboxes = np_methods.bboxes_clip(rbboxes)\n",
    "                rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=-1)\n",
    "                rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, \n",
    "                                                                  nms_threshold=0.45)\n",
    "                #Resize bboxes to original image shape. Note: useless for Resize.WARP!\n",
    "                bboxes = np.concatenate(localb, 0)\n",
    "                           \n",
    "                image_ = np.uint8(img) *255\n",
    "                img_ = image_.copy()\n",
    "                #visualize_bbox(img_, rbboxes)\n",
    "                \n",
    "                img = image_.copy()\n",
    "                #visualize_bbox(img, bboxes)\n",
    "                img_ = image_.copy()\n",
    "                #visualize_bbox(img_, gbboxes_)\n",
    "                \n",
    "                img = image_.copy()\n",
    "\n",
    "                \n",
    "                for i in range(6):\n",
    "                    #pass\n",
    "                    box.append(rlocalisations[i][np.where(rpredictions_2[i] > 0.5)].shape[0])\n",
    "                #error.append((gbboxes_.shape[0] - rbboxes.shape[0]))\n",
    "                if bboxes.shape[0] > 0:\n",
    "                    bboxes_uni = np.vstack({tuple(row) for row in bboxes})\n",
    "                else:\n",
    "                    bboxes_uni = np.array([])\n",
    "                error.append((gbboxes_.shape[0] - bboxes_uni.shape[0]))\n",
    "            print sum(error)\n",
    "            print sum(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07        0.04949747  0.04041452  0.03130495  0.02645751  0.02213594]\n",
      "[ 0.07        0.09899495  0.12124356  0.15652476  0.1852026   0.22135943]\n",
      "[[ 0.9868421]\n",
      " [ 0.9868421]]\n"
     ]
    }
   ],
   "source": [
    "print text_anchors[0][2]\n",
    "print text_anchors[0][3]\n",
    "print text_anchors[0][1][-1,-1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(4, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.86915886,  0.27287585,  0.90420568,  0.48692811],\n",
       "       [ 0.05140188,  0.24183005,  0.28037384,  0.75      ],\n",
       "       [ 0.86915886,  0.501634  ,  0.90420568,  0.73856211]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print rbboxes.shape\n",
    "print gbboxes_.shape\n",
    "#\n",
    "np_methods.bboxes_clip(gbboxes_)\n",
    "np.vstack({tuple(row) for row in bboxes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.51170921,  0.86333787,  2.25124788, -0.83508193],\n",
       "       [ 2.72015834,  1.11456442,  0.97418404,  0.44198248],\n",
       "       [ 2.29895329,  1.31877029,  0.13300337,  1.28316283],\n",
       "       [ 1.76216304,  0.86333787,  2.25124788, -0.83508193],\n",
       "       [ 1.36496568,  1.11456442,  0.97418404,  0.44198248],\n",
       "       [ 1.15360653,  1.31877029,  0.13300337,  1.28316283],\n",
       "       [ 0.96517646,  1.57623196, -0.75868422,  2.17484999],\n",
       "       [ 0.01261697,  0.86333787,  2.25124788, -0.83508193],\n",
       "       [ 0.00977306,  1.11456442,  0.97418404,  0.44198248],\n",
       "       [ 0.00825974,  1.31877029,  0.13300337,  1.28316283],\n",
       "       [ 0.0069106 ,  1.57623196, -0.75868422,  2.17484999],\n",
       "       [-1.73692966,  0.86333787,  2.25124788, -0.83508193],\n",
       "       [-1.34542   ,  1.11456442,  0.97418404,  0.44198248],\n",
       "       [-1.13708735,  1.31877029,  0.13300337,  1.28316283],\n",
       "       [-0.95135552,  1.57623196, -0.75868422,  2.17484999],\n",
       "       [-3.48647523,  0.86333787,  2.25124788, -0.83508193],\n",
       "       [-2.70061231,  1.11456442,  0.97418404,  0.44198248],\n",
       "       [-2.28243375,  1.31877029,  0.13300337,  1.28316283],\n",
       "       [ 3.51170921,  0.86333787,  2.25124788, -0.83508193],\n",
       "       [ 2.72015834,  1.11456442,  0.97418404,  0.44198248],\n",
       "       [ 2.29895329,  1.31877029,  0.13300337,  1.28316283],\n",
       "       [ 1.76216304,  0.86333787,  2.25124788, -0.83508193],\n",
       "       [ 1.36496568,  1.11456442,  0.97418404,  0.44198248],\n",
       "       [ 1.15360653,  1.31877029,  0.13300337,  1.28316283],\n",
       "       [ 0.96517646,  1.57623196, -0.75868422,  2.17484999],\n",
       "       [ 0.01261697,  0.86333787,  2.25124788, -0.83508193],\n",
       "       [ 0.00977306,  1.11456442,  0.97418404,  0.44198248],\n",
       "       [ 0.00825974,  1.31877029,  0.13300337,  1.28316283],\n",
       "       [ 0.0069106 ,  1.57623196, -0.75868422,  2.17484999],\n",
       "       [-1.73692966,  0.86333787,  2.25124788, -0.83508193],\n",
       "       [-1.34542   ,  1.11456442,  0.97418404,  0.44198248],\n",
       "       [-1.13708735,  1.31877029,  0.13300337,  1.28316283],\n",
       "       [-0.95135552,  1.57623196, -0.75868422,  2.17484999],\n",
       "       [-3.48647523,  0.86333787,  2.25124788, -0.83508193],\n",
       "       [-2.70061231,  1.11456442,  0.97418404,  0.44198248],\n",
       "       [-2.28243375,  1.31877029,  0.13300337,  1.28316283]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlocalisations[2][np.where(rpredictions_2[2] > 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4)\n",
      "(0, 4)\n",
      "(36, 4)\n",
      "(4, 4)\n",
      "(0, 4)\n",
      "(0, 4)\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print rlocalisations[i][np.where(rpredictions_2[i] > 0.5)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty.  Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2fa34eee1be1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0misess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_anchors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/python/anaconda/envs/tensorflow2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/python/anaconda/envs/tensorflow2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[0m\u001b[1;32m    906\u001b[0m                          'graph before calling run().')\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The Session graph is empty.  Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "isess.run(text_anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def visualize_bbox(image, bboxes):\n",
    "    \"\"\"\n",
    "    Input: image (height, width, channels)\n",
    "           bboxes (numof bboxes, 4) in order(ymin, xmin, ymax, xmax)\n",
    "                  range(0,1) \n",
    "    \"\"\"\n",
    "    numofbox = bboxes.shape[0]\n",
    "    width = image.shape[1]\n",
    "    height = image.shape[0]\n",
    "    def norm(x):\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        else:\n",
    "            if x > 1:\n",
    "                x = 1\n",
    "        return x\n",
    "    xmin = [int(i * width) for i in bboxes[:,1]]\n",
    "    ymin = [int(i * height) for i in bboxes[:,0]]\n",
    "    ymax = [int(i * height) for i in bboxes[:,2]]\n",
    "    xmax = [int(i * width) for i in bboxes[:,3]]\n",
    "\n",
    "    for i in range(numofbox):\n",
    "        image = cv2.rectangle(image,(xmin[i],ymin[i]),\n",
    "                             (xmax[i],ymax[i]),(0,255,255))\n",
    "    #print [ymin,xmin,ymax,xmax]\n",
    "    skio.imshow(image)\n",
    "    skio.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "min_dim = 300\n",
    "min_ratio = 20\n",
    "max_ratio = 95\n",
    "step = int(math.floor((max_ratio - min_ratio) / (6 - 2)))\n",
    "min_sizes = []\n",
    "max_sizes = []\n",
    "for ratio in xrange(min_ratio, max_ratio + 1, step):\n",
    "    min_sizes.append(min_dim * ratio / 100.)\n",
    "    max_sizes.append(min_dim * (ratio + step) / 100.)\n",
    "min_sizes = [min_dim * 10 / 100.] + min_sizes\n",
    "max_sizes = [[]] + max_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(fname='result.csv',X=a,delimiter=',',fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], 114.0, 168.0, 222.0, 276.0, 330.0]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.0, 60.0, 114.0, 168.0, 222.0, 276.0]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf_2.7",
   "language": "python",
   "name": "tensorflow2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
