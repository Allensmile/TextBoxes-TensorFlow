{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## test \n",
    "## 1. anchor_boxes\n",
    "## 2. groudtruth encode\n",
    "## 3. bboxes decode(not yet finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.insert(0,'../processing/')\n",
    "sys.path.insert(0,'../')\n",
    "from image_processing2 import *\n",
    "import ssd_vgg_preprocessing\n",
    "import tf_extended as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.31666666666666665, 0.43333333333333335, 0.55, 0.6666666666666666, 0.7833333333333332, 0.8999999999999999]\n"
     ]
    }
   ],
   "source": [
    "img_shape=(300, 300)\n",
    "num_classes=2\n",
    "feat_layers=['conv_4_3', 'fc7', 'conv6_2', 'conv7_2', 'conv8_2', 'pool6']\n",
    "feat_shapes=[(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)]\n",
    "scale_range=[0.20, 0.90]\n",
    "anchor_ratios=[1,2,3,5,7,10]\n",
    "normalizations=[20, -1, -1, -1, -1, -1]\n",
    "prior_scaling=[0.1, 0.1, 0.2, 0.2]\n",
    "\n",
    "step = (scale_range[1] - scale_range[0]) / len(feat_shapes)\n",
    "scales = [scale_range[0] + i * step for i in range(len(feat_shapes)+1)]\n",
    "print scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 38, 2, 1)\n",
      "[ 0.02368421  0.01674727  0.01367409  0.0105919   0.00895179  0.0074896 ]\n",
      "(38, 38, 2, 6)\n"
     ]
    }
   ],
   "source": [
    "def textbox_anchor_one_layer(img_shape,\n",
    "                             feat_size,\n",
    "                             ratios,\n",
    "                             scale,\n",
    "                             offset = 0.5,\n",
    "                             dtype=np.float32):\n",
    "    # Follow the papers scheme\n",
    "    # 12 ahchor boxes with out sk' = sqrt(sk * sk+1)\n",
    "    y, x = np.mgrid[0:feat_size[0], 0:feat_size[1]] + 0.5\n",
    "    y = y.astype(dtype) / feat_size[0]\n",
    "    x = x.astype(dtype) / feat_size[1]\n",
    "\n",
    "    x_offset = x\n",
    "    y_offset = y + offset\n",
    "    x_out = np.stack((x, x_offset), -1)\n",
    "    y_out = np.stack((y, y_offset), -1)\n",
    "    y_out = np.expand_dims(y_out, axis=-1)\n",
    "    x_out = np.expand_dims(x_out, axis=-1)\n",
    "\n",
    "    # \n",
    "    num_anchors = 6\n",
    "    h = np.zeros((num_anchors, ), dtype=dtype)\n",
    "    w = np.zeros((num_anchors, ), dtype=dtype)\n",
    "    for i ,r in enumerate(ratios):\n",
    "        h[i] = scale / math.sqrt(r) / feat_size[0]\n",
    "        w[i] = scale * math.sqrt(r) / feat_size[1]\n",
    "    return y_out, x_out, h, w\n",
    "\n",
    "y,x,h,w = textbox_anchor_one_layer((300,300), (38,38),(1,2,3,5,7,10),0.9)\n",
    "print y.shape\n",
    "print h\n",
    "print (y -h).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n",
      "(38, 38, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "def textbox_achor_all_layers(img_shape,\n",
    "                           layers_shape,\n",
    "                           anchor_ratios,\n",
    "                           scales,\n",
    "                           offset=0.5,\n",
    "                           dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Compute anchor boxes for all feature layers.\n",
    "    \"\"\"\n",
    "    layers_anchors = []\n",
    "    for i, s in enumerate(layers_shape):\n",
    "        anchor_bboxes = textbox_anchor_one_layer(img_shape, s,\n",
    "                                                 anchor_ratios,\n",
    "                                                 scales[i],\n",
    "                                                 offset=offset, dtype=dtype)\n",
    "        layers_anchors.append(anchor_bboxes)\n",
    "    return layers_anchors\n",
    "\n",
    "layers_anchors = textbox_achor_all_layers((300,300), feat_shapes,anchor_ratios,scales)\n",
    "print len(layers_anchors)\n",
    "print len(layers_anchors[0])\n",
    "print layers_anchors[0][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# =========================================================================== #\n",
    "# TensorFlow implementation of Text Boxes encoding / decoding.\n",
    "# =========================================================================== #\n",
    "\n",
    "def tf_text_bboxes_encode_layer(bboxes,\n",
    "                               anchors_layer, num,\n",
    "                               matching_threshold=0.1,\n",
    "                               prior_scaling=[0.1, 0.1, 0.2, 0.2],\n",
    "                               dtype=tf.float32):\n",
    "    \n",
    "    \"\"\"\n",
    "    Encode groundtruth labels and bounding boxes using Textbox anchors from\n",
    "    one layer.\n",
    "\n",
    "    Arguments:\n",
    "      bboxes: Nx4 Tensor(float) with bboxes relative coordinates;\n",
    "      anchors_layer: Numpy array with layer anchors;\n",
    "      matching_threshold: Threshold for positive match with groundtruth bboxes;\n",
    "      prior_scaling: Scaling of encoded coordinates.\n",
    "\n",
    "    Return:\n",
    "      (target_localizations, target_scores): Target Tensors.\n",
    "    # thisi is a binary problem, so target_score and tartget_labels are same.\n",
    "    \"\"\"\n",
    "    # Anchors coordinates and volume.\n",
    "\n",
    "    yref, xref, href, wref = anchors_layer\n",
    "    print yref.shape\n",
    "    print href.shape\n",
    "    print bboxes.shape\n",
    "    ymin = yref - href / 2.\n",
    "    xmin = xref - wref / 2.\n",
    "    ymax = yref + href / 2.\n",
    "    xmax = xref + wref / 2. \n",
    "    vol_anchors = (xmax - xmin) * (ymax - ymin)\n",
    "    \n",
    "    # Initialize tensors...\n",
    "    shape = (yref.shape[0], yref.shape[1], yref.shape[2], href.size)\n",
    "    # all follow the shape(feat.size, feat.size, 2, 6)\n",
    "    #feat_labels = tf.zeros(shape, dtype=tf.int64)\n",
    "    feat_scores = tf.zeros(shape, dtype=dtype)\n",
    "\n",
    "    feat_ymin = tf.zeros(shape, dtype=dtype)\n",
    "    feat_xmin = tf.zeros(shape, dtype=dtype)\n",
    "    feat_ymax = tf.ones(shape, dtype=dtype)\n",
    "    feat_xmax = tf.ones(shape, dtype=dtype)\n",
    "\n",
    "    def jaccard_with_anchors(bbox):\n",
    "        \"\"\"\n",
    "        Compute jaccard score between a box and the anchors.\n",
    "        \"\"\"\n",
    "        int_ymin = tf.maximum(ymin, bbox[0])\n",
    "        int_xmin = tf.maximum(xmin, bbox[1])\n",
    "        int_ymax = tf.minimum(ymax, bbox[2])\n",
    "        int_xmax = tf.minimum(xmax, bbox[3])\n",
    "        h = tf.maximum(int_ymax - int_ymin, 0.)\n",
    "        w = tf.maximum(int_xmax - int_xmin, 0.)\n",
    "        # Volumes.\n",
    "        inter_vol = h * w\n",
    "        union_vol = vol_anchors - inter_vol \\\n",
    "            + (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "        jaccard = tf.div(inter_vol, union_vol)\n",
    "        return jaccard\n",
    "    \n",
    "    \"\"\"\n",
    "    # never use in Textbox\n",
    "    def intersection_with_anchors(bbox):\n",
    "        '''\n",
    "        Compute intersection between score a box and the anchors.\n",
    "        '''\n",
    "        int_ymin = tf.maximum(ymin, bbox[0])\n",
    "        int_xmin = tf.maximum(xmin, bbox[1])\n",
    "        int_ymax = tf.minimum(ymax, bbox[2])\n",
    "        int_xmax = tf.minimum(xmax, bbox[3])\n",
    "        h = tf.maximum(int_ymax - int_ymin, 0.)\n",
    "        w = tf.maximum(int_xmax - int_xmin, 0.)\n",
    "        inter_vol = h * w\n",
    "        scores = tf.div(inter_vol, vol_anchors)\n",
    "        return scores\n",
    "    \"\"\"\n",
    "    \n",
    "    def condition(i, feat_scores,\n",
    "                  feat_ymin, feat_xmin, feat_ymax, feat_xmax):\n",
    "        \"\"\"Condition: check label index.\n",
    "        \"\"\"\n",
    "        #r = tf.less(i, tf.shape(bboxes)[0])\n",
    "        r = tf.less(i, num)\n",
    "        return r\n",
    "\n",
    "    def body(i, feat_scores,feat_ymin, feat_xmin, feat_ymax, feat_xmax):\n",
    "        \"\"\"Body: update feature labels, scores and bboxes.\n",
    "        Follow the original SSD paper for that purpose:\n",
    "          - assign values when jaccard > 0.5;\n",
    "          - only update if beat the score of other bboxes.\n",
    "        \"\"\"\n",
    "        # Jaccard score.\n",
    "        bbox = bboxes[i]\n",
    "        jaccard = jaccard_with_anchors(bbox)\n",
    "        # Mask: check threshold + scores + no annotations + num_classes.\n",
    "        mask = tf.greater(jaccard, feat_scores)\n",
    "        mask = tf.logical_and(mask, tf.greater(jaccard, matching_threshold))\n",
    "        #mask = tf.logical_and(mask, feat_scores > -0.5)\n",
    "        #mask = tf.logical_and(mask, label < num_classes)\n",
    "        imask = tf.cast(mask, tf.int64)\n",
    "        fmask = tf.cast(mask, dtype)\n",
    "        # Update values using mask.\n",
    "        #feat_labels = imask * label + (1 - imask) * feat_labels\n",
    "        feat_scores = tf.where(mask, jaccard, feat_scores)\n",
    "\n",
    "        feat_ymin = fmask * bbox[0] + (1 - fmask) * feat_ymin\n",
    "        feat_xmin = fmask * bbox[1] + (1 - fmask) * feat_xmin\n",
    "        feat_ymax = fmask * bbox[2] + (1 - fmask) * feat_ymax\n",
    "        feat_xmax = fmask * bbox[3] + (1 - fmask) * feat_xmax\n",
    "\n",
    "        # Check no annotation label: ignore these anchors...\n",
    "        #interscts = intersection_with_anchors(bbox)\n",
    "        #mask = tf.logical_and(interscts > ignore_threshold,\n",
    "        #                     label == no_annotation_label)\n",
    "        # Replace scores by -1.\n",
    "        #feat_scores = tf.where(mask, -tf.cast(mask, dtype), feat_scores)\n",
    "\n",
    "        return [i+1, feat_scores,\n",
    "                feat_ymin, feat_xmin, feat_ymax, feat_xmax]\n",
    "    # Main loop definition.\n",
    "\n",
    "    i = 0\n",
    "    [i,feat_scores,\n",
    "     feat_ymin, feat_xmin,\n",
    "     feat_ymax, feat_xmax] = tf.while_loop(condition, body,\n",
    "                                           [i, feat_scores,\n",
    "                                            feat_ymin, feat_xmin,\n",
    "                                            feat_ymax, feat_xmax])\n",
    "    '''\n",
    "    for i, bbox in enumerate(tf.unpack(bboxes, axis=0)):\n",
    "        [i,feat_scores,feat_ymin, \n",
    "        feat_xmin, feat_ymax, feat_xmax] = body(i, feat_scores,\n",
    "                                                feat_ymin, feat_xmin, \n",
    "                                                feat_ymax, feat_xmax,bbox)\n",
    "    '''\n",
    "    # Transform to center / size.\n",
    "    feat_cy = (feat_ymax + feat_ymin) / 2.\n",
    "    feat_cx = (feat_xmax + feat_xmin) / 2.\n",
    "    feat_h = feat_ymax - feat_ymin\n",
    "    feat_w = feat_xmax - feat_xmin\n",
    "    # Encode features.\n",
    "    feat_cy = (feat_cy - yref) / href / prior_scaling[0]\n",
    "    feat_cx = (feat_cx - xref) / wref / prior_scaling[1]\n",
    "    feat_h = tf.log(feat_h / href) / prior_scaling[2]\n",
    "    feat_w = tf.log(feat_w / wref) / prior_scaling[3]\n",
    "    # Use SSD ordering: x / y / w / h instead of ours.\n",
    "    feat_localizations = tf.stack([feat_cx, feat_cy, feat_w, feat_h], axis=-1)\n",
    "    return feat_localizations, feat_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_text_bboxes_encode(bboxes,\n",
    "                         anchors, num,\n",
    "                         matching_threshold=0.3,\n",
    "                         prior_scaling=[0.1, 0.1, 0.2, 0.2],\n",
    "                         dtype=tf.float32,\n",
    "                         scope='text_bboxes_encode'):\n",
    "    \"\"\"Encode groundtruth labels and bounding boxes using SSD net anchors.\n",
    "    Encoding boxes for all feature layers.\n",
    "\n",
    "    Arguments:\n",
    "      bboxes: Nx4 Tensor(float) with bboxes relative coordinates;\n",
    "      anchors: List of Numpy array with layer anchors;\n",
    "      matching_threshold: Threshold for positive match with groundtruth bboxes;\n",
    "      prior_scaling: Scaling of encoded coordinates.\n",
    "\n",
    "    Return:\n",
    "      (target_labels, target_localizations, target_scores):\n",
    "        Each element is a list of target Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.name_scope('text_bboxes_encode'):\n",
    "        target_labels = []\n",
    "        target_localizations = []\n",
    "        target_scores = []\n",
    "        for i, anchors_layer in enumerate(anchors):\n",
    "            with tf.name_scope('bboxes_encode_block_%i' % i):\n",
    "                t_loc, t_scores = \\\n",
    "                    tf_text_bboxes_encode_layer(bboxes, anchors_layer, num,\n",
    "                                                matching_threshold,\n",
    "                                               prior_scaling, dtype)\n",
    "                target_localizations.append(t_loc)\n",
    "                target_scores.append(t_scores)\n",
    "        return target_localizations, target_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf_2.7",
   "language": "python",
   "name": "tensorflow2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
