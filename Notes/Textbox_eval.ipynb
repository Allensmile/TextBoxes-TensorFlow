{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "import scipy.io as sio\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "sys.path.insert(0,'../processing/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nets import txtbox_300, textbox_common, np_methods\n",
    "from processing import txt_preprocessing\n",
    "from processing import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input placeholder.\n",
    "net_shape = (300, 300)\n",
    "data_format = 'NHWC'\n",
    "img_input = tf.placeholder(tf.uint8, shape=(None, None, 3))\n",
    "# Evaluation pre-processing: resize to SSD net shape.\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = txt_preprocessing.preprocess_for_eval(\n",
    "    img_input, None, None, net_shape, data_format, resize=txt_preprocessing.Resize.WARP_RESIZE)\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# Define the SSD model.\n",
    "#reuse = True if 'net' in locals() else None\n",
    "net = txtbox_300.TextboxNet()\n",
    "with slim.arg_scope(net.arg_scope(data_format=data_format)):\n",
    "    localisations, predictions,  _ = net.net(image_4d, is_training=False, reuse=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Restore SSD model.\n",
    "ckpt_filename = '../checkpoints/model.ckpt-1337.meta'\n",
    "# ckpt_filename = '../checkpoints/VGG_VOC0712_SSD_300x300_ft_iter_120000.ckpt'\n",
    "isess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "#saver = tf.train.import_meta_graph(ckpt_filename)\n",
    "saver.restore(isess, '../checkpoints/model.ckpt-1337')\n",
    "\n",
    "# SSD default anchor boxes.\n",
    "anchors = net.anchors(net_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "flogits = []\n",
    "fgscores = []\n",
    "flocalisations = []\n",
    "fglocalisations = []\n",
    "for i in range(len(predictions)):\n",
    "    flogits.append(tf.reshape(predictions[i], [-1, 2]))\n",
    "    flocalisations.append(tf.reshape(localisations[i], [-1, 4]))\n",
    "# And concat the crap!\n",
    "logits = tf.concat(flogits, axis=0)\n",
    "localisations = tf.concat(flocalisations, axis=0)\n",
    "rimg, rpredictions, rlocalisations, rbbox_img = isess.run([image_4d, logits, localisations, bbox_img],\n",
    "                                                              feed_dict={img_input: img})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23280, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpredictions.shape\n",
    "#isess.run(tf.nn.softmax(tf.constant([[1.,3.],[2.0,5.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Main image processing routine.\n",
    "def process_image(img, select_threshold=0.5, nms_threshold=.45, net_shape=(300, 300)):\n",
    "    # Run SSD network.\n",
    "    rimg, rpredictions, rlocalisations, rbbox_img = isess.run([image_4d, predictions, localisations, bbox_img],\n",
    "                                                              feed_dict={img_input: img})\n",
    "    \n",
    "    #rpredictions[0] = rpredictions[0]\n",
    "    # Get classes and bboxes from the net outputs.\n",
    "    rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n",
    "            rpredictions, rlocalisations, anchors,\n",
    "            select_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)\n",
    "    \n",
    "    rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=20)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\n",
    "    # Resize bboxes to original image shape. Note: useless for Resize.WARP!\n",
    "    rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\n",
    "    return rclasses, rscores, rbboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-9c1040fe718d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/ICDAR2013/ICDAR-Test-Images/img_105.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrbboxes\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# visualization.bboxes_draw_on_img(img, rclasses, rscores, rbboxes, visualization.colors_plasma)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplt_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrbboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-23d2587c4648>\u001b[0m in \u001b[0;36mprocess_image\u001b[0;34m(img, select_threshold, nms_threshold, net_shape)\u001b[0m\n\u001b[1;32m     10\u001b[0m     rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n\u001b[1;32m     11\u001b[0m             \u001b[0mrpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrlocalisations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             select_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mrbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_methods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbboxes_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbbox_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrbboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiaodiu/Documents/github/projecttextbox/TextBoxes-TensorFlow/nets/np_methods.pyc\u001b[0m in \u001b[0;36mssd_bboxes_select\u001b[0;34m(predictions_net, localizations_net, anchors_net, select_threshold, img_shape, num_classes, decode)\u001b[0m\n\u001b[1;32m    118\u001b[0m         classes, scores, bboxes = ssd_bboxes_select_layer(\n\u001b[1;32m    119\u001b[0m             \u001b[0mpredictions_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocalizations_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors_net\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             select_threshold, img_shape, num_classes, decode)\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0ml_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0ml_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiaodiu/Documents/github/projecttextbox/TextBoxes-TensorFlow/nets/np_methods.pyc\u001b[0m in \u001b[0;36mssd_bboxes_select_layer\u001b[0;34m(predictions_layer, localizations_layer, anchors_layer, select_threshold, img_shape, num_classes, decode)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# First decode localizations features if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mlocalizations_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssd_bboxes_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocalizations_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Reshape features to: Batches x N x N_labels | 4.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiaodiu/Documents/github/projecttextbox/TextBoxes-TensorFlow/nets/np_methods.pyc\u001b[0m in \u001b[0;36mssd_bboxes_decode\u001b[0;34m(feat_localizations, anchor_bboxes, prior_scaling)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0ml_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_localizations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     feat_localizations = np.reshape(feat_localizations,\n\u001b[0;32m---> 35\u001b[0;31m                                     (-1, l_shape[-2], l_shape[-1]))\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0myref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor_bboxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mxref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "img = mpimg.imread('../data/ICDAR2013/ICDAR-Test-Images/img_105.jpg')\n",
    "rclasses, rscores, rbboxes =  process_image(img)\n",
    "\n",
    "# visualization.bboxes_draw_on_img(img, rclasses, rscores, rbboxes, visualization.colors_plasma)\n",
    "visualization.plt_bboxes(img, rclasses, rscores, rbboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf_2.7",
   "language": "python",
   "name": "tensorflow2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
